from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
sc=SparkContext("local")
spark=SparkSession(sc)

from pyspark.sql.types import StructType, StringType, DoubleType,
IntegerType, LongType

schema1=StructType().add("Year",StrintType(),True).add("Quarter",StringType(),True).add("Average",DoubleType(),True).add("Booked_Seats",IntegerType(),True)

df1=spark.read.format("csv").option("header",True).schema(schema1).load("hdfs://nameservice1/user/bigcdac432582/training2/airlines.csv")

df1.registerTempTable("airlines")

df2=spark.sql("select year, booked_seats from airlines order by Booked_seats desc")
df2.show()

df3=spark.sql("select Year, sum(Booked_seats*Average) as total from airlines group by year order by total desc")
df3.show()

df4=spark.sql("select sum(Booked_seats*Average) as total,year,quarter from airlines group by year,quarter order by total desc")
df4.show()

df2=df2.repartition(1)
df3=df2.repartition(1)
df4=df2.repartition(1)

df2.write.csv("hdfs://nameservice1/user/bigcdac432582/training2/out1")
df3.write.csv("hdfs://nameservice1/user/bigcdac432582/training2/out2")
df4.write.csv("hdfs://nameservice1/user/bigcdac432582/training2/out3")
